# 1. Simple Linear Regression 복습
 - 하나의 정보로부터 하나의 결론을 짓는 모델이다.
 - H(x) = Wx + b
 - ex) 공부 시간에 따른 시험 성적 예측
 

<br>
<hr>
<br>

# 2. Multivariate Linear Regression 이론
 - 복수의 정보로부터 하나의 결롯을 짓는 모델이다.
 - H(x) = w1x1 + w2x2 + w3x3 + b (입력 변수가 3개면 weight도 3개!)
 - ex) 첫번째 퀴즈 성적, 두번째 퀴즈 성적, 세번째 퀴즈 성적을 통해 final 시험을 예측한다.


<br>
<hr>
<br>

# 3. Naive Data Representation

### (1) 데이터 정의
# 데이터
x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]]) # 첫번째 퀴즈 성적
x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]]) # 두번째 퀴즈 성적
x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]]) # 세번째 퀴즈 성적
y_train = torch.FloatTensor([[152], [185], [180], [196], [142]]) # final 시험

<br>

### (2) Hypothesis function 정의 - 기본
 - 아래와 같이 입력 변수의 수 만큼 weight를 곱했다.
 - 하.지.만. 입력 변수가 1000개라면..?
hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b

<br>

### (3) Hypothesis function 정의 - matmul
 - matmul()로 한번에 정의가 가능하다. x의 길이가 바뀌어도 코드를 바꿀 필요가 없고, 속도도 더 빠르다.
hypothesis = x_train.matmul(W) + b

<br>
<hr>
<br>

# 4. Matrix Data Representation

<br>
<hr>
<br>

# 5. Multivariate Linear Regression

<br>
<hr>
<br>

# 6. nn.Module 소개

<br>
<hr>
<br>

# 7. F.mse_loss 소개
