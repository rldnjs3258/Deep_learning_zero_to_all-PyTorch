# 1. Convolution 이란?
 - 이미지는 컴퓨터가 받아드리기에 Gray-scale 혹은 RGB의 숫자이다. 또한 필터는 사용자가 찾고자 하는 피쳐의 숫자 값들이다.
 - Convolution은 이미지 위에서 Stride 값 만큼 fiter(Kernel)을 이동시키면서 이미지와 필터가 겹쳐지는 부분의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 연산이다.
 - Input 이미지에서 Stride 만큼 필터를 움직이며 연산되므로, output의 크기는 Input보다 줄어든다!
 
# 2. Stride and Padding
### (1) Stride
 - filter를 한 번에 얼마나 이동 할 것인가를 정의한다.

<br>

### (2) Padding
 - Zero-padding
 - 패딩을 씌우고 싶은 곳 상하좌우로 0을 둘러싼다. (패딩을 씌운다.)
 - Padding에 1 값을 주면, 패딩을 1칸 씌운다.
 
# 3. Pytorch에서 Conv2d 이용하기
### (1) Pytorch에서 Conv2d의 도큐먼트 살펴보기
 - torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True)
 - 파리미터에 순서대로 인풋 채널, 아웃풋 채널, 커널(필터) 크기, Stride, Padding 등을 선언해 주면 된다.
 - 커널(필터) 크기를 정사각형으로 설정하려면 3 과 같이 설정하면 되고, 직사각형으로 설정하려면 (2, 4)와 같이 설정하면 된다.

<br>

### (2) Conv2d 예제
 - Convolution을 하나 만들어 보자! (인풋 채널 1, 3*3 크기의 채널 1 짜리 커널)
 - 여기서 인풋 채널 1의 뜻은 인풋 이미지가 Gray-scale이라는 것이고(3일 경우 RGB), 채널 1 짜리 커널의 뜻은 커널(필터)의 갯수가 1개 라는 것이다.

# Convolution을 하나 만들어 보자!
conv = nn.Conv2d(1, 1, 3) # 인풋 채널 1, 커널이 한 장이므로 아웃풋 채널도 1, 커널 크기는 3

<br>

### (3) Conv2d 입력 형태
 - 앞에서 Conv2d로 Convolution을 만들어 놨다. 생성해 놓은 Convolution에는 어떤 값을 넣어서 이용할 수 있을까?
 - Conv2d에는 Tensor 타입을 입력해야 한다.
 - Conv2d에 들어가는 입력 값은 (batch_size, input channel, input height, input width)이다.

conv = nn.Conv2d(1, 1, 3) # convolution을 만들어 놨다.
output = conv(batch_size, input channel, input height, input width) # conv에 값들을 넣어서 이용하여, input 이미지에 convolution을 돌린 output을 구하자!

<br>

### (4) 요약 정리!
 - Input 이미지에 Convolution을 돌려서 Outpu을 얻으려면?
#### 1. Convolution 만들기
 - 인풋 채널, 아웃풋 채널, 필터 크기, Stride, Padding 등을 설정해서 Convolution을 만들어 놓자.
 - 필터, Stride, Padding 등을 설정해 Convolution의 전체적인 아웃라인을 만들어 놓는다고 생각하면 된다!
#### 2. Convolution 이용하기
 - 만들어 둔 conv에 batch_size, input channel, input height, input width 값을 넣어 Convolution을 이용하자.
 - 만들어 둔 conv에 input 이미지의 높이, 너비 등을 입력하여 실질적으로 Convolution을 이용한다고 생각하면 된다!


# 4. Convolution의 Output 크기 예상하기
 - Input 이미지에 Convolution을 돌린 Output 이미지의 크기를 예상해 보자.
 - Output size = (input size - filter size + (2 * padding))/Stride + 1

<br>

### ex 1) Input Image가 정사각형인 경우!
 - input image size = 227 * 227
 - filter size = 11 * 11
 - stride = 4
 - pradding = 0
 - output image size = ((227 - 11 + 0)/4) + 1 = 55 => 55 * 55

<br>

### ex 2)
 - input image size = 64 * 64
 - filter size = 7 * 7
 - stride = 2
 - pradding = 0
 - output image size = ((64 - 7 + 0)/2) + 1 = 29.3 = 29 (소수점은 과감히 버린다!) => 29 * 29

<br>

### ex 3)
 - input image size = 32 * 32
 - filter size = 5 * 5
 - stride = 1
 - pradding = 2
 - output image size = ((32 - 5 + (2 * 2))/1) + 1 = 32 => 32 * 32

<br>

### ex 4) Input Image가 직사각형인 경우!
 - input image size = 32 * 64
 - filter size = 5 * 5
 - stride = 1
 - pradding = 0
 - output image size = (((32, 64) - 5 + 0)/1) + 1 = (27, 59) + 1 = (28, 60) => 28 * 60
 
<br>

### ex 5)
 - input image size = 64 * 32
 - filter size = 3 * 3
 - stride = 1
 - pradding = 1
 - output image size = (((64, 32) - 3 + 2)/1) + 1 = (63, 31) + 1 = (64, 32) => 64 * 32
 
# 5. Convolution의 Output 크기 예상한 것 직접 코드로 확인해보기
### ex 1)

# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 11, stride = 4, padding = 0) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 227, 227) # batch size : 1, input channel : 1, input size : 227 * 227

# Convolution 이용하기
output = conv(inputs)

output.shape # 55 * 55

<br>

### ex 2)

# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 7, stride = 2, padding = 0) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 64, 64) # batch size : 1, input channel : 1, input size : 64 * 64

# Convolution 이용하기
output = conv(inputs)

output.shape # 29 * 29

<br>

### ex 3)

# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 5, stride = 1, padding = 2) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 32, 32) # batch size : 1, input channel : 1, input size : 32 * 32

# Convolution 이용하기
output = conv(inputs)

output.shape # 32 * 32

<br>

### ex 4)

# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 5, stride = 1) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 32, 64) # batch size : 1, input channel : 1, input size : 32 * 64

# Convolution 이용하기
output = conv(inputs)

output.shape # 28 * 60

<br>

### ex 5)

# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 3, stride = 1, padding = 1) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 64, 32) # batch size : 1, input channel : 1, input size : 64 * 32

# Convolution 이용하기
output = conv(inputs)

output.shape # 64 * 32


# 6. Neuron(Perceptron)과 Convolution
 - Neuron과 Convolution의 관계를 살펴보자.
### (1) Convolution을 구성하는 filter의 각 값들이 Perceptron의 weight로 들어간다.
 - ex) filter가 3 * 3의 크기라면 필터 안의 각 값들이 Perceptron의 weight로 9개의 class로 나뉘어져 들어간다.

<br>

### (2) Input 이미지에서 filter 크기만큼의 각 값들이 Perceptron에 각 클래스로 나뉘어져 들어가 연산된다.
 - ex) Input 이미지에서 3 * 3 크기의 각 값들이 Perceptron에 9개의 class로 나뉘어져 들어가 연산된다.

<br>

### (3) 곱하고 더하는 연산이 진행 된 뒤, bias를 더한다.
 - ex) 1 + 3 + 1 + 1 + 2 = 8 => 8 + bias
