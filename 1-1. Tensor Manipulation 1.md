# 1. Vector, Matrix and Tensor
### (1) Vector, Matrix and Tensor
 - 벡터 : 1차원으로 이루어진 행렬
 - 행렬 : 2차원으로 이루어진 행렬
 - 텐서 : 3차원으로 이루어진 행렬
 
 <br>
 
### (2) PyTorch Tensor Shape Convection
#### 1) 2D에서의 텐서
 - |t| = (batch size(세로) * dimension(가로))
 
 ex) |t| = batch size(64) * dim(256)
 
#### 2) 3D에서의 텐서
 - |t| = (batch size(세로) * width(가로) * height(깊이))
 
#### 3) 3D에서의 텐서 - NLP
 - |t| = (batch size(세로) * length(가로) * dim(깊이))
 - dim * length가 batch size만큼 쌓여 있다.
 
 <br>
 
<br>
<hr>
<br>

# 2. NumPy Review
 - NumPy와 PyTorch는 작성법이 아주 유사하고, 직관적이라서 이해가 쉽다.
### (1) Import
```
import numpy as np #넘파이
import torch #파이토치
```

<br>

### (2) 1D Array with NumPy
```
t = np.array([0., 1., 2., 3., 4., 5., 6.]) #0~6을 리스트로 선언하여 array로 만듦
print(t)

print('Rank of t: ', t.ndim) #t는 1차원 벡터
print('Shape of t: ', t.shape) #t에는 1차원이 7개 들어있음

print('t[0] t[1] t[-1] = ', t[0], t[1], t[-1]) #요소 확인
print('t[2:5] t[4:-1] = ', t[2:5], t[4:-1]) #Slicing으로 요소 확인
print('t[:2] t[3:] = ', t[:2], t[3:]) #Slicing으로 요소 확인
```

<br>

### (3) 2D Array with Numpy
```
t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]]) #2차원 리스트를 선언하여 array로 만듦
print(t)

print('Rank of t: ', t.ndim) #t는 2차원 행렬
print('Shape of t: ', t.shape) #t에는 4*3의 요소가 들어있음
```

<br>
<hr>
<br>

# 3. PyTorch Tensor Allocation
### (1) 1D Array with PyTorch

<br>
<hr>
<br>

# 4. Matrix Multiplication

<br>
<hr>
<br>

# 5. Other Basic Ops
