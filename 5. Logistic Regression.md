# 1. Reminder
 - Logistic Regression은 Binary Classification이다. 0 또는 1로 분류함!
 - Sigmoid 함수를 이용해 0과 1에 근사하게 한다.

<br>
<hr>
<br>

# 2. Import

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

torch.manual_seed(1) # 결과 재현을 위한 시드 설정


<br>
<hr>
<br>

# 3. Training Data
 - x_data(독립변수) : 6 * 2
 - y_data(종속변수) : 6 * 1
x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]
y_data = [[0], [0], [0], [1], [1], [1]]

x_train = torch.FloatTensor(x_data) # FloatTensor화!
y_train = torch.FloatTensor(y_data)

print(x_train.shape)
print(y_train.shape)


<br>
<hr>
<br>

# 4. Computing the Hypothesis
print('e^1 equals: ', torch.exp(torch.FloatTensor([1]))) #torch.exp를 통해 exponential을 이용 가능!

W = torch.zeros((2, 1), requires_grad = True) # W 정의, 학습 가능 설정
b = torch.zeros(1, requires_grad = True) # b 정의, 학습 가능 설정

hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b))) # 모델 정의

print(hypothesis)
print(hypothesis.shape)


<br>
<hr>
<br>


# 4. Evaluation


<br>
<hr>
<br>


# 5. Higher Implementation
