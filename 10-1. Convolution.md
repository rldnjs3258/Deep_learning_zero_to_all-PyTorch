# 1. Convolution 이란?
 - 이미지는 컴퓨터가 받아드리기에 Gray-scale 혹은 RGB의 숫자이다. 또한 필터는 사용자가 찾고자 하는 피쳐의 숫자 값들이다.
 - Convolution은 필터 값이 input 이미지와 얼마나 겹치는가를 연산하여 출력한다. 값이 클 수록 사용자가 찾고자 하는 피쳐(필터)와 닮은 부분이다!
 - Convolution은 이미지 위에서 Stride 값 만큼 fiter(Kernel)을 이동시키면서 이미지와 필터가 겹쳐지는 부분의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 연산이다.
 - Input 이미지에서 Stride 만큼 필터를 움직이며 연산되므로, output의 크기는 Input보다 줄어든다!
 
<br>
<hr>
<br>
 
# 2. Stride and Padding
### (1) Stride
 - filter를 한 번에 얼마나 이동 할 것인가를 정의한다.

<br>

### (2) Padding
 - Zero-padding
 - 패딩을 씌우고 싶은 곳 상하좌우로 0을 둘러싼다. (패딩을 씌운다.)
 - Padding에 1 값을 주면, 패딩을 1칸 씌운다.


<br>
<hr>
<br>
 

# 3. Pytorch에서 Conv2d 이용하기
### (1) Pytorchd의 Conv2d 도큐먼트 살펴보기
 - torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True)
 - 파리미터에 순서대로 인풋 채널, 아웃풋 채널, 커널(필터) 크기, Stride, Padding 등을 선언해 주면 된다.
 - 커널(필터) 크기를 정사각형으로 설정하려면 3 과 같이 설정하면 되고, 직사각형으로 설정하려면 (2, 4)와 같이 설정하면 된다.

<br>

### (2) Conv2d 예제
 - Convolution을 하나 만들어 보자! (인풋 채널 1, 3 * 3 크기의 채널 1 짜리 커널)
 - 여기서 인풋 채널 1의 뜻은 인풋 이미지가 Gray-scale이라는 것이고(3일 경우 RGB), 채널 1 짜리 커널의 뜻은 커널(필터)의 갯수가 1개 라는 것이다.

```python
# Convolution을 하나 만들어 보자!
conv = nn.Conv2d(1, 1, 3) # 인풋 채널 1, 커널이 한 장이므로 아웃풋 채널도 1, 커널 크기는 3
```

<br>

### (3) Conv2d 입력 형태
 - 앞에서 Conv2d로 Convolution을 만들어 놨다. 생성해 놓은 Convolution에는 어떤 값을 넣어서 이용할 수 있을까?
 - Conv2d에는 Tensor 타입을 입력해야 한다.
 - Conv2d에 들어가는 입력 값은 (batch_size, input channel, input height, input width)이다.

```python
conv = nn.Conv2d(1, 1, 3) # convolution을 만들어 놨다.
output = conv(batch_size, input channel, input height, input width) # conv에 값들을 넣어서 이용하여, input 이미지에 convolution을 돌린 output을 구하자!
```

<br>

### (4) 요약 정리!
 - Input 이미지에 Convolution을 돌려서 Output을 얻으려면?
#### 1. Convolution 만들기
 - 인풋 채널, 아웃풋 채널, 필터 크기, Stride, Padding 등을 설정해서 Convolution을 만들어 놓자.
 - 필터, Stride, Padding 등을 설정해 Convolution의 전체적인 아웃라인을 만들어 놓는다고 생각하면 된다!
 
#### 2. Convolution 이용하기
 - 만들어 둔 conv에 batch_size, input channel, input height, input width 값을 넣어 Convolution을 이용하자.
 - 만들어 둔 conv에 input 이미지의 높이, 너비 등을 입력하여 실질적으로 Convolution을 이용한다고 생각하면 된다!

<br>
<hr>
<br>

# 4. Convolution의 Output 크기 예상하기
 - Input 이미지에 Convolution을 돌린 Output 이미지의 크기를 예상해 보자.
 - Output size = (input size - filter size + (2 * padding))/Stride + 1

<br>

### ex 1) Input Image가 정사각형인 경우!
 - input image size = 227 * 227
 - filter size = 11 * 11
 - stride = 4
 - pradding = 0
 - output image size = ((227 - 11 + 0)/4) + 1 = 55 => 55 * 55

<br>

### ex 2)
 - input image size = 64 * 64
 - filter size = 7 * 7
 - stride = 2
 - pradding = 0
 - output image size = ((64 - 7 + 0)/2) + 1 = 29.3 = 29 (소수점은 과감히 버린다!) => 29 * 29

<br>

### ex 3)
 - input image size = 32 * 32
 - filter size = 5 * 5
 - stride = 1
 - pradding = 2
 - output image size = ((32 - 5 + (2 * 2))/1) + 1 = 32 => 32 * 32

<br>

### ex 4) Input Image가 직사각형인 경우!
 - input image size = 32 * 64
 - filter size = 5 * 5
 - stride = 1
 - pradding = 0
 - output image size = (((32, 64) - 5 + 0)/1) + 1 = (27, 59) + 1 = (28, 60) => 28 * 60
 
<br>

### ex 5)
 - input image size = 64 * 32
 - filter size = 3 * 3
 - stride = 1
 - pradding = 1
 - output image size = (((64, 32) - 3 + 2)/1) + 1 = (63, 31) + 1 = (64, 32) => 64 * 32

<br>
<hr>
<br>

# 5. Convolution의 Output 크기 예상한 것 직접 코드로 확인 해보기
### ex 1)

```python
# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 11, stride = 4, padding = 0) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 227, 227) # batch size : 1, input channel : 1, input size : 227 * 227

# Convolution 이용하기
output = conv(inputs)

output.shape # 55 * 55
```

<br>

### ex 2)

```python
# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 7, stride = 2, padding = 0) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 64, 64) # batch size : 1, input channel : 1, input size : 64 * 64

# Convolution 이용하기
output = conv(inputs)

output.shape # 29 * 29
```

<br>

### ex 3)

```python
# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 5, stride = 1, padding = 2) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 32, 32) # batch size : 1, input channel : 1, input size : 32 * 32

# Convolution 이용하기
output = conv(inputs)

output.shape # 32 * 32
```

<br>

### ex 4)

```python
# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 5, stride = 1) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 32, 64) # batch size : 1, input channel : 1, input size : 32 * 64

# Convolution 이용하기
output = conv(inputs)

output.shape # 28 * 60
```

<br>

### ex 5)

```python
# 라이브러리 로드
import torch
import torch.nn as nn

# Convolution 만들기
conv = nn.Conv2d(1, 1, 3, stride = 1, padding = 1) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.tensor(1, 1, 64, 32) # batch size : 1, input channel : 1, input size : 64 * 32

# Convolution 이용하기
output = conv(inputs)

output.shape # 64 * 32
```

<br>
<hr>
<br>


# 6. Neuron(Perceptron)과 Convolution
 - Neuron과 Convolution의 관계를 살펴보자.
### (1) Convolution을 구성하는 filter의 각 값들이 Perceptron의 weight로 들어간다.
 - ex) filter가 3 * 3의 크기라면 필터 안의 각 값들이 Perceptron의 weight로 9개의 class로 나뉘어져 들어간다.

<br>

### (2) Input 이미지에서 filter 크기만큼의 각 값들이 Perceptron에 각 클래스로 나뉘어져 들어가 연산된다.
 - ex) Input 이미지에서 3 * 3 크기의 각 값들이 Perceptron에 9개의 class로 나뉘어져 들어가 연산된다.

<br>

### (3) 곱하고 더하는 연산이 진행 된 뒤, bias를 더한다. (filter도 bias를 가질 수 있음!)
 - ex) 1 + 3 + 1 + 1 + 2 = 8 => 8 + bias

<br>
<hr>
<br>


# 7. Pooling
### (1) Pooling이란?
 - Pooling 연산은 이미지의 사이즈를 줄이거나, fully-connected 연산을 대체하기 위해 사용한다.

<br>

### (2) Max Pooling
 - Max Pooling의 Size를 2로 설정하면, 값들 중 2 * 2 사이즈 이내에서 가장 큰 값들을 취한다. 
 - ex) 

<Max Pooling 전>
| 1 | 9 | 3 | 7 |
|---|:---:|---:|---:|
| 4 | 5 | 2 | 8 |
| 7 | 3 | 9 | 0 |
| 1 | 2 | 3 | 3 |


<Max Pooling 후>
| 9 | 8 |
|---|:---:|
| 7 | 9 |

<br>


### (3) Average Pooling
 - Average Pooling의 Size를 2로 설정하면, 값들 중 2 * 2 사이즈 이내에서 평균 값들을 취한다. 

<Average Pooling 전>
| 1 | 1 | 2 | 2 |
|---|:---:|---:|---:|
| 1 | 1 | 2 | 2 |
| 3 | 3 | 1 | 2 |
| 3 | 3 | 1 | 4 |


<Average Pooling 후>
| 1 | 2 |
|---|:---:|
| 3 | 2 |

<br>
<hr>
<br>

# 8. PyTorch의 MaxPool2d 도큐먼트
 - torch.nn.MaxPool2d(kernel_size, stride = None, padding = 0)
 - 다른 값들은 default 값이 잘 설정되어 있으므로 대체로 앞에서 배운 Size만 잘 설정하면 된다.

<br>
<hr>
<br>

# 9. CNN 모델 만들어보기!

```python
# 라이브러리 로드
import torch
import torch.nn as nn

# conv에 넣기 위해 input을 tensor로 만들기
inputs = torch.Tensor(1, 1, 28, 28)

# Convolution 만들기
conv1 = nn.Conv2d(1, 5, 5) # input 채널 : 1, output 채널 : 5, filter 크기 : 5

# Pool 만들기
pool = nn.MaxPool2d(2) # 2 * 2 사이즈 이내에서 가장 큰 값을 취함

# Convolution 이용하기
out = conv1(input) # input 이미지에 convolution을 돌린 결과가 out에 담김

# Pool 이용하기
out2 = pool(out) # out을 pool 한 결과가 out2에 담김

out.size() # 24 * 24. Conv 해서 사이즈가 줄어듦!
out2.size() # 12 * 12. Pool 해서 사이즈가 줄어듦!
```

<br>
<hr>
<br>

# 10. 추가 내용 (몰라도 됨)
 - Convolution : 필터 값이 기존의 이미지와 얼마나 겹치는 가를 출력한다. Convolution은 필터를 상하좌우로 뒤집은 채로 돌린다!
 - Cross-correlation : 필터 값이 기존의 이미지와 얼마나 겹치는 가를 출력한다. Cross-correlation은 필터를 뒤집지 않은 채로 돌린다!
 - 이 내용은 딥러닝을 공부하면서 크게 알아두지는 않아도 되는 내용이다.
