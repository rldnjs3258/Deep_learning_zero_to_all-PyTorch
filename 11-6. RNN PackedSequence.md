# 1. Sequential data
 - Text
 - Audio
 - 시퀀스 데이터들은 길이가 정해지지 않은 데이터가 많다. 텍스트를 길이를 지정해서 보내거나, 오디오를 일정 시간에 맞게만 채집하거나 하지 않기 때문

<br>
<hr>
<br>

# 2. 시퀀스의 길이를 맞추는 방법
### (1) 시퀀스의 길이를 맞춰야 하는 이유
 - 길이가 각각 다른 시퀀스의 길이를 맞추면, 시퀀스 데이터에 배치를 이용해서 연산할 수 있다.

<br>

### (2) 시퀀스의 길이를 맞추는 방법
 - Padding
 - Packing


<br>
<hr>
<br>


# 3. Padding Method
 - 길이가 각각 다른 시퀀스 데이터의 길이를 패딩을 이용해 맞추는 방법이다.
 - 가장 긴 시퀀스의 길이에 맞춰 나머지 데이터들 뒷 부분을 <pad> 토큰으로 채워 넣는 방식이다.
 - 장점 : 패딩을 이용해 길이가 맞춰지면, batch 등을 이용할 수 있기 때문에 연산하기 굉장히 편리해진다!
 - 단점 : 계산하지 않아도 될 <pad> 부분까지 불필요하게 계산해야 한다.


<br>
<hr>
<br>


# 4. Packing Method
 - 각 데이터를 길이에 따라 내림차순 정리하고, 시퀀스 길이에 대한 정보를 저장하는 방법이다.
 - '시퀀스 길이 정보 + 실제 데이터'를 같이 갖고 있는 자료구조를 Packed Sequence라고 한다.
 - 장점 : <pad>를 안 쓰기 때문에 Padding에 비해 효율적인 계산을 할 수 있다.
 - 단점 : 내림차순으로 정렬해야 한다. 구현시 Padding에 비해 복잡하다.


<br>
<hr>
<br>


# 5. PyTorch 라이브러리 함수
 - pad_sequence : PaddedSequence를 만들 수 있다.
 - pack_sequence : PackedSequence를 만들 수 있다.
 - pack_padded_sequence : Padding이 된 것을 PackedSequence로 바꿀 수 있다.
 - pad_packed_sequence : Packed 된 것을 PaddedSequence로 바꿀 수 있다.
